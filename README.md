# CoherenceGuard — Technical AI Governance Challenge

## Purpose
A **deterministic AI governance engine** demonstrating strict separation of:
**Evidence (measurement) ≠ Interpretation (policy) ≠ Decision (action)**.

This repository is **not a classifier** and **not ML**.
It implements frozen, monotonic evidence signals with **swappable policy interpreters** and auditable trace output.

---

## What This Is
- A **governance system** suitable for regulatory review.
- Deterministic, reproducible, auditable.
- Evidence is benchmark-agnostic and never tuned to score.
- Policy behavior is explicit, versioned, and replaceable.

## What This Is Not
- Not a content classifier.
- Not a trained model.
- Not optimized by adjusting sensors.

---

## Architecture

### 1) Evidence Layer (Frozen)
- Measures signals only.
- No thresholds, no categories, no verdicts.
- Deterministic and monotonic.
- Implemented in: `src/validation/validate.py` (`evaluate_evidence`)

### 2) Interpretation Layer (Policy)
- Applies thresholds, weights, priors.
- Multiple interpreters supported.
- Benchmark alignment occurs **only here**.
- Implemented in: `src/interpreters/`

Available interpreters:
- `gov_baseline_v1` — conservative, real-world governance
- `apart_challenge_v1` — benchmark-aligned policy

Interpreter selection per run (PowerShell):
```powershell
$env:COHERENCEGUARD_INTERPRETER = 'gov_baseline_v1'
python .\run_validation.py
```

### 3) Decision Layer
- Maps interpreted severity → actions.
- Action logic is jurisdiction-specific.
- Implemented in: `src/decisions/policy_default.py`

---

## Usage
Run with a chosen policy:

```powershell
$env:COHERENCEGUARD_INTERPRETER = 'apart_challenge_v1'
python .\run_validation.py
```

Outputs:
- `test_results.csv` — evidence + interpretation + verdict
- `trace_output.jsonl` — audit trace per item (generated by `make_trace_jsonl.py`)

---

## Evidence Signals (Examples)
- `dscore` — direct harm capability (0–3)
- `iscore` — instructional enablement (0–3)
- `oscore` — obfuscation / evasion intent (0–2)
- `sigma` — continuous risk metric [0,1]
- `kappa`, `tau` — stability proxies

Evidence definitions are frozen by design.

---

## Benchmark Note
Benchmark performance is a function of the chosen interpreter, not evidence manipulation.

---

## License
MIT
