## Problem
Frontier AI labs are training systems that could pose international risks. Countries want 
agreements on safe development. Labs need ways to demonstrate compliance without exposing 
competitive advantages.

## Method
The technical infrastructure to make this possible doesnt exist yet. We have policy frameworks 
without verification systems. International agreements without monitoring tools. Compliance 
requirements without practical implementation paths.

## Findings
This hackathon focuses on building that missing infrastructure. Youll have one intensive

## Impact
Judging Criteria Dimension 1: Impact Potential & Innovation How much would this matter for AI safety if it worked? How innovative is it? For scores of 4-5: is this actually new to the field, or replicating recent work? Score Description 1 Negligible. No clear problem addressed, or no meaningful novelty. 2 Limited. Addresses a real problem but with a generic or well-trodden approach. Incremental at best. 3 Moderate. Clear problem with a reasonable approach; some novelty in framing or method beyond routine application of existing tools. 4 Significant. Important problem with an original approach, or identifies a neglected problem area. A valuable contribution others could build on. 5 Exceptional. Tackles a critical AI safety problem with a genuinely novel approach, or opens a new research direction. Clear theory of change. Youd be excited to share this with researchers in the area.

## Limitations & Dual-Use Appendix
Dimension 2: Execution Quality How sound are methodology, implementation, and findings? Score Description 1 Seriously flawed. Methodology broken, results uninterpretable, or implementation doesnt work. 2 Weak. Approach has significant gaps: missing validation, flawed experimental design, or incomplete implementation. 3 Competent. Technically solid given the short duration. Methodology makes sense, results are interpretable, limitations acknowledged, work builds toward clear conclusions. 4 Strong. Thorough methodology with convincing validation. Results clearly support conclusions. Immediately useful for future work. 5 Exceptional. Ambitious scope executed rigorously. Surprising findings, novel methods, or unusually robust validation. Dimension 3: Presentation & Clarity How clearly are work, findings, and impact potential communicated? Score Description 1 Incomprehensible. Cannot determine what the project is actually claiming or doing. 2 Hard to follow. Key information buried, missing, or diluted by excessive length. Significant effort to extract main points. 3 Clear enough. Can understand the problem, approach, and results without undue effort. Core content clearly present: problem, method, findings, limitations. 4 Well presented. Easy to follow, well-structured, appropriate level of detail. Target audience would get it quickly. 5 Exceptionally clear. A pleasure to read. Complex ideas made accessible. Could serve as a model for how to present this type of work.
